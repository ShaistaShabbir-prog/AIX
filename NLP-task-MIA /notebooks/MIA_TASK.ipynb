{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ShaistaShabbir-prog/AIX/blob/dev/NLP-task-MIA%20/notebooks/MIA_TASK.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lgNIgOAuA4rX"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GrFfCRvQynhC",
        "outputId": "0df44401-0c84-4be0-88f1-a36c5dbcaa98"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')\n",
        "#Run in case you need to mount google drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "qpQgcRFTVwcG"
      },
      "outputs": [],
      "source": [
        "!rm -rf AIX\n",
        "# in case of re running of the notebook"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Luxse7FW0q20",
        "outputId": "9a86c7fe-0326-44d2-d52e-37a1739b7bfa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'AIX'...\n",
            "remote: Enumerating objects: 209, done.\u001b[K\n",
            "remote: Counting objects: 100% (67/67), done.\u001b[K\n",
            "remote: Compressing objects: 100% (64/64), done.\u001b[K\n",
            "remote: Total 209 (delta 15), reused 3 (delta 3), pack-reused 142 (from 1)\u001b[K\n",
            "Receiving objects: 100% (209/209), 60.17 KiB | 12.03 MiB/s, done.\n",
            "Resolving deltas: 100% (111/111), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/ShaistaShabbir-prog/AIX.git\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QlOEoHT-1Ry9",
        "outputId": "153a4932-0b31-4c8b-ffce-fa1442120463"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Errno 2] No such file or directory: 'AIX/'\n",
            "/content/AIX/NLP-task-MIA/src/AIX\n"
          ]
        }
      ],
      "source": [
        "%cd AIX/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yoq9Rxtl1DGu",
        "outputId": "053596a4-5ba0-4c8a-c017-8dfbd219120f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Branch 'dev' set up to track remote branch 'dev' from 'origin'.\n",
            "Switched to a new branch 'dev'\n",
            "Already up to date.\n"
          ]
        }
      ],
      "source": [
        "!git fetch origin\n",
        "!git checkout dev\n",
        "!git pull\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "boepgu5Mkc4V",
        "outputId": "7204e325-22c5-4534-d693-2103f9bacc7d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "python3.10-venv is already the newest version (3.10.12-1~22.04.7).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 55 not upgraded.\n"
          ]
        }
      ],
      "source": [
        "\n",
        "!apt install python3.10-venv\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T2K2GRP7kyou",
        "outputId": "30f10687-6a44-4642-9de4-7e063fdea394"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NLP-task-MIA  README.md  requirements.txt\n"
          ]
        }
      ],
      "source": [
        "\n",
        "!ls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "22b6aa03-4f70-4b75-fc71-6d4a5bca91bf",
        "id": "24_8ZrbulqRH"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r0% [Working]\r            \rGet:1 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease [3,626 B]\n",
            "Hit:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease\n",
            "Get:3 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ Packages [60.9 kB]\n",
            "Get:4 http://security.ubuntu.com/ubuntu jammy-security InRelease [129 kB]\n",
            "Hit:5 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Get:6 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [128 kB]\n",
            "Hit:7 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Hit:8 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Get:9 https://r2u.stat.illinois.edu/ubuntu jammy InRelease [6,555 B]\n",
            "Hit:10 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Hit:11 http://archive.ubuntu.com/ubuntu jammy-backports InRelease\n",
            "Get:12 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 Packages [2,788 kB]\n",
            "Get:13 http://archive.ubuntu.com/ubuntu jammy-updates/restricted amd64 Packages [3,543 kB]\n",
            "Fetched 6,659 kB in 3s (2,126 kB/s)\n",
            "Reading package lists... Done\n",
            "W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "build-essential is already the newest version (12.9ubuntu3).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 56 not upgraded.\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "python3-dev is already the newest version (3.10.6-1~22.04.1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 56 not upgraded.\n"
          ]
        }
      ],
      "source": [
        "!apt-get update\n",
        "!apt-get install build-essential\n",
        "!apt-get install python3-dev\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1gRn9bvv1b6P",
        "outputId": "28a9226a-97f2-4895-b2bf-6600ffbb2fa5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting numpy==1.21.6 (from -r /content/AIX/requirements.txt (line 4))\n",
            "  Using cached numpy-1.21.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.1 kB)\n",
            "Collecting pandas==1.3.5 (from -r /content/AIX/requirements.txt (line 5))\n",
            "  Using cached pandas-1.3.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Collecting matplotlib==3.8.4 (from -r /content/AIX/requirements.txt (line 6))\n",
            "  Using cached matplotlib-3.8.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.8 kB)\n",
            "Collecting seaborn==0.11.2 (from -r /content/AIX/requirements.txt (line 7))\n",
            "  Using cached seaborn-0.11.2-py3-none-any.whl.metadata (2.3 kB)\n",
            "Collecting scikit-learn==1.0.2 (from -r /content/AIX/requirements.txt (line 8))\n",
            "  Using cached scikit_learn-1.0.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (10 kB)\n",
            "Collecting tensorflow==2.10.0 (from -r /content/AIX/requirements.txt (line 9))\n",
            "  Using cached tensorflow-2.10.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.1 kB)\n",
            "Collecting keras==2.10.0 (from -r /content/AIX/requirements.txt (line 10))\n",
            "  Using cached keras-2.10.0-py2.py3-none-any.whl.metadata (1.3 kB)\n",
            "Collecting nltk==3.7 (from -r /content/AIX/requirements.txt (line 11))\n",
            "  Using cached nltk-3.7-py3-none-any.whl.metadata (2.8 kB)\n",
            "Collecting tensorflow-hub==0.12.0 (from -r /content/AIX/requirements.txt (line 12))\n",
            "  Using cached tensorflow_hub-0.12.0-py2.py3-none-any.whl.metadata (1.7 kB)\n",
            "Collecting scikit-image==0.19.3 (from -r /content/AIX/requirements.txt (line 13))\n",
            "  Using cached scikit_image-0.19.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (8.0 kB)\n",
            "Collecting opencv-python==4.5.3.56 (from -r /content/AIX/requirements.txt (line 14))\n",
            "  Using cached opencv-python-4.5.3.56.tar.gz (89.2 MB)\n",
            "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
            "  \n",
            "  \u001b[31m×\u001b[0m \u001b[32mpip subprocess to install build dependencies\u001b[0m did not run successfully.\n",
            "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
            "  \u001b[31m╰─>\u001b[0m See above for output.\n",
            "  \n",
            "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25herror\n",
            "\u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
            "\n",
            "\u001b[31m×\u001b[0m \u001b[32mpip subprocess to install build dependencies\u001b[0m did not run successfully.\n",
            "\u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
            "\u001b[31m╰─>\u001b[0m See above for output.\n",
            "\n",
            "\u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n"
          ]
        }
      ],
      "source": [
        "!python3 -m venv nlp_task_mia_env\n",
        "!source nlp_task_mia_env/bin/activate\n",
        "\n",
        "\n",
        "!pip install -r /content/AIX/requirements.txt\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dxSK9Lw187Ra",
        "outputId": "8cb92e2d-d6ca-4c93-8c5e-722e6a6d1187"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: loguru in /usr/local/lib/python3.10/dist-packages (0.7.3)\n"
          ]
        }
      ],
      "source": [
        "!pip install loguru\n",
        "# you might need to install few packages separately"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uI2vMuH2P3rn",
        "outputId": "547da773-3bc5-4b21-da99-2569e82bcdc7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r0% [Working]\r            \rHit:1 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease\n",
            "Hit:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease\n",
            "Get:3 http://security.ubuntu.com/ubuntu jammy-security InRelease [129 kB]\n",
            "Hit:4 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Get:5 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [128 kB]\n",
            "Hit:6 https://r2u.stat.illinois.edu/ubuntu jammy InRelease\n",
            "Hit:7 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Hit:8 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Hit:9 http://archive.ubuntu.com/ubuntu jammy-backports InRelease\n",
            "Hit:10 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Fetched 257 kB in 2s (129 kB/s)\n",
            "Reading package lists... Done\n",
            "W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "build-essential is already the newest version (12.9ubuntu3).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 56 not upgraded.\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "python3-dev is already the newest version (3.10.6-1~22.04.1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 56 not upgraded.\n"
          ]
        }
      ],
      "source": [
        "!apt-get update\n",
        "!apt-get install build-essential\n",
        "!apt-get install python3-dev\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5B9i7VryQfUv",
        "outputId": "3379ec9e-677c-494b-b65e-56a9da8fb2ed"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tf-models-official==2.10\n",
            "  Downloading tf_models_official-2.10.0-py2.py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: Cython in /usr/local/lib/python3.10/dist-packages (from tf-models-official==2.10) (3.0.11)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from tf-models-official==2.10) (11.0.0)\n",
            "Requirement already satisfied: gin-config in /usr/local/lib/python3.10/dist-packages (from tf-models-official==2.10) (0.5.0)\n",
            "Requirement already satisfied: google-api-python-client>=1.6.7 in /usr/local/lib/python3.10/dist-packages (from tf-models-official==2.10) (2.151.0)\n",
            "Requirement already satisfied: immutabledict in /usr/local/lib/python3.10/dist-packages (from tf-models-official==2.10) (4.2.1)\n",
            "Requirement already satisfied: kaggle>=1.3.9 in /usr/local/lib/python3.10/dist-packages (from tf-models-official==2.10) (1.6.17)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from tf-models-official==2.10) (3.8.0)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.10/dist-packages (from tf-models-official==2.10) (1.26.4)\n",
            "Requirement already satisfied: oauth2client in /usr/local/lib/python3.10/dist-packages (from tf-models-official==2.10) (4.1.3)\n",
            "INFO: pip is looking at multiple versions of tf-models-official to determine which version is compatible with other requirements. This could take a while.\n",
            "\u001b[31mERROR: Ignored the following yanked versions: 3.4.11.39, 3.4.11.41, 4.4.0.40, 4.4.0.42, 4.4.0.44, 4.5.5.62, 4.7.0.68, 4.8.0.74\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: Could not find a version that satisfies the requirement opencv-python-headless==4.5.2.52 (from tf-models-official) (from versions: 3.4.10.37, 3.4.11.43, 3.4.11.45, 3.4.13.47, 3.4.15.55, 3.4.16.59, 3.4.17.61, 3.4.17.63, 3.4.18.65, 4.3.0.38, 4.4.0.46, 4.5.1.48, 4.5.3.56, 4.5.4.58, 4.5.4.60, 4.5.5.64, 4.6.0.66, 4.7.0.72, 4.8.0.76, 4.8.1.78, 4.9.0.80, 4.10.0.82, 4.10.0.84)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for opencv-python-headless==4.5.2.52\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip install tf-models-official==2.10\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n8aa43y98_iY",
        "outputId": "9595d7de-b24e-4420-fb32-0f1b5e561e0c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/AIX/NLP-task-MIA/src\n",
            "AIX\t\t __init__.py\tmain.py\t\t\t __pycache__\n",
            "attack_model.py  logs\t\tmodel_evaluator.py\t settings.py\n",
            "data_loader.py\t lstm_model.py\tprivacy_preservation.py\n",
            "Collecting TensorFlow-privacy\n",
            "  Downloading tensorflow_privacy-0.9.0-py3-none-any.whl.metadata (763 bytes)\n",
            "Requirement already satisfied: absl-py==1.*,>=1.0 in /usr/local/lib/python3.10/dist-packages (from TensorFlow-privacy) (1.4.0)\n",
            "Requirement already satisfied: dm-tree==0.1.8 in /usr/local/lib/python3.10/dist-packages (from TensorFlow-privacy) (0.1.8)\n",
            "Collecting dp-accounting==0.4.3 (from TensorFlow-privacy)\n",
            "  Downloading dp_accounting-0.4.3-py3-none-any.whl.metadata (1.8 kB)\n",
            "Requirement already satisfied: numpy~=1.21 in /usr/local/lib/python3.10/dist-packages (from TensorFlow-privacy) (1.26.4)\n",
            "Collecting packaging~=22.0 (from TensorFlow-privacy)\n",
            "  Downloading packaging-22.0-py3-none-any.whl.metadata (3.1 kB)\n",
            "Requirement already satisfied: scikit-learn==1.*,>=1.0 in /usr/local/lib/python3.10/dist-packages (from TensorFlow-privacy) (1.5.2)\n",
            "Requirement already satisfied: scipy~=1.9 in /usr/local/lib/python3.10/dist-packages (from TensorFlow-privacy) (1.13.1)\n",
            "Collecting tensorflow-estimator~=2.4 (from TensorFlow-privacy)\n",
            "  Downloading tensorflow_estimator-2.15.0-py2.py3-none-any.whl.metadata (1.3 kB)\n",
            "Collecting tensorflow-probability~=0.22.0 (from TensorFlow-privacy)\n",
            "  Downloading tensorflow_probability-0.22.1-py2.py3-none-any.whl.metadata (13 kB)\n",
            "Requirement already satisfied: tensorflow~=2.4 in /usr/local/lib/python3.10/dist-packages (from TensorFlow-privacy) (2.17.1)\n",
            "Requirement already satisfied: attrs>=22 in /usr/local/lib/python3.10/dist-packages (from dp-accounting==0.4.3->TensorFlow-privacy) (24.2.0)\n",
            "Requirement already satisfied: mpmath~=1.2 in /usr/local/lib/python3.10/dist-packages (from dp-accounting==0.4.3->TensorFlow-privacy) (1.3.0)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn==1.*,>=1.0->TensorFlow-privacy) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn==1.*,>=1.0->TensorFlow-privacy) (3.5.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.4->TensorFlow-privacy) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.4->TensorFlow-privacy) (24.3.25)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.4->TensorFlow-privacy) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.4->TensorFlow-privacy) (0.2.0)\n",
            "Requirement already satisfied: h5py>=3.10.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.4->TensorFlow-privacy) (3.12.1)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.4->TensorFlow-privacy) (18.1.1)\n",
            "Requirement already satisfied: ml-dtypes<0.5.0,>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.4->TensorFlow-privacy) (0.4.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.4->TensorFlow-privacy) (3.4.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.4->TensorFlow-privacy) (4.25.5)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.4->TensorFlow-privacy) (2.32.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.4->TensorFlow-privacy) (75.1.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.4->TensorFlow-privacy) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.4->TensorFlow-privacy) (2.5.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.4->TensorFlow-privacy) (4.12.2)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.4->TensorFlow-privacy) (1.17.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.4->TensorFlow-privacy) (1.68.1)\n",
            "Requirement already satisfied: tensorboard<2.18,>=2.17 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.4->TensorFlow-privacy) (2.17.1)\n",
            "Requirement already satisfied: keras>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.4->TensorFlow-privacy) (3.5.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.4->TensorFlow-privacy) (0.37.1)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from tensorflow-probability~=0.22.0->TensorFlow-privacy) (4.4.2)\n",
            "Requirement already satisfied: cloudpickle>=1.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow-probability~=0.22.0->TensorFlow-privacy) (3.1.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow~=2.4->TensorFlow-privacy) (0.45.1)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow~=2.4->TensorFlow-privacy) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow~=2.4->TensorFlow-privacy) (0.0.8)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow~=2.4->TensorFlow-privacy) (0.13.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow~=2.4->TensorFlow-privacy) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow~=2.4->TensorFlow-privacy) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow~=2.4->TensorFlow-privacy) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow~=2.4->TensorFlow-privacy) (2024.8.30)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow~=2.4->TensorFlow-privacy) (3.7)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow~=2.4->TensorFlow-privacy) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow~=2.4->TensorFlow-privacy) (3.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.18,>=2.17->tensorflow~=2.4->TensorFlow-privacy) (3.0.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.2.0->tensorflow~=2.4->TensorFlow-privacy) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.2.0->tensorflow~=2.4->TensorFlow-privacy) (2.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.2.0->tensorflow~=2.4->TensorFlow-privacy) (0.1.2)\n",
            "Downloading tensorflow_privacy-0.9.0-py3-none-any.whl (323 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m323.2/323.2 kB\u001b[0m \u001b[31m23.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dp_accounting-0.4.3-py3-none-any.whl (104 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m104.8/104.8 kB\u001b[0m \u001b[31m11.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading packaging-22.0-py3-none-any.whl (42 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.6/42.6 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tensorflow_estimator-2.15.0-py2.py3-none-any.whl (441 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m442.0/442.0 kB\u001b[0m \u001b[31m40.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tensorflow_probability-0.22.1-py2.py3-none-any.whl (6.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m101.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: tensorflow-probability, tensorflow-estimator, packaging, dp-accounting, TensorFlow-privacy\n",
            "  Attempting uninstall: tensorflow-probability\n",
            "    Found existing installation: tensorflow-probability 0.24.0\n",
            "    Uninstalling tensorflow-probability-0.24.0:\n",
            "      Successfully uninstalled tensorflow-probability-0.24.0\n",
            "  Attempting uninstall: packaging\n",
            "    Found existing installation: packaging 24.2\n",
            "    Uninstalling packaging-24.2:\n",
            "      Successfully uninstalled packaging-24.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "langchain-core 0.3.24 requires packaging<25,>=23.2, but you have packaging 22.0 which is incompatible.\n",
            "sphinx 8.1.3 requires packaging>=23.0, but you have packaging 22.0 which is incompatible.\n",
            "xarray 2024.10.0 requires packaging>=23.1, but you have packaging 22.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed TensorFlow-privacy-0.9.0 dp-accounting-0.4.3 packaging-22.0 tensorflow-estimator-2.15.0 tensorflow-probability-0.22.1\n"
          ]
        }
      ],
      "source": [
        "%cd /content/AIX/NLP-task-MIA/src\n",
        "!ls\n",
        "!pip install -U TensorFlow-privacy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IHjrVABdpPUw",
        "outputId": "2bf96a16-efe7-4a64-e98f-51ea7aad39bf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pydantic-settings in /usr/local/lib/python3.10/dist-packages (2.7.0)\n",
            "Requirement already satisfied: pydantic>=2.7.0 in /usr/local/lib/python3.10/dist-packages (from pydantic-settings) (2.10.3)\n",
            "Requirement already satisfied: python-dotenv>=0.21.0 in /usr/local/lib/python3.10/dist-packages (from pydantic-settings) (1.0.1)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.7.0->pydantic-settings) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.1 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.7.0->pydantic-settings) (2.27.1)\n",
            "Requirement already satisfied: typing-extensions>=4.12.2 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.7.0->pydantic-settings) (4.12.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install pydantic-settings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zCTjLjDk9T5q",
        "outputId": "a532b9e6-7533-49a4-bd68-39bb905ddd22"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/AIX/NLP-task-MIA/src\n",
            "2024-12-16 20:01:40.598633: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-12-16 20:01:40.636391: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-12-16 20:01:40.645858: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-12-16 20:01:40.677901: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2024-12-16 20:01:42.586078: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "\u001b[32m2024-12-16 20:01:44.792\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m105\u001b[0m - \u001b[1mStarting the main process.\u001b[0m\n",
            "\u001b[32m2024-12-16 20:01:44.792\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m22\u001b[0m - \u001b[1mInitializing evaluator and loading data.\u001b[0m\n",
            "\u001b[32m2024-12-16 20:01:48.969\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m30\u001b[0m - \u001b[1mData loaded successfully. Starting baseline model training.\u001b[0m\n",
            "\u001b[32m2024-12-16 20:01:48.969\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mlstm_model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m63\u001b[0m - \u001b[1mTraining the model...\u001b[0m\n",
            "\u001b[32m2024-12-16 20:01:48.969\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mlstm_model\u001b[0m:\u001b[36mbuild\u001b[0m:\u001b[36m35\u001b[0m - \u001b[1mBuilding the LSTM model...\u001b[0m\n",
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "I0000 00:00:1734379308.997652   39542 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "I0000 00:00:1734379309.061577   39542 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "I0000 00:00:1734379309.061911   39542 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "I0000 00:00:1734379309.062566   39542 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "I0000 00:00:1734379309.062843   39542 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "I0000 00:00:1734379309.063043   39542 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "I0000 00:00:1734379309.256344   39542 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "I0000 00:00:1734379309.256818   39542 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2024-12-16 20:01:49.258088: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:47] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "I0000 00:00:1734379309.258280   39542 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2024-12-16 20:01:49.258496: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13949 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\n",
            "\u001b[32m2024-12-16 20:01:49.305\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mlstm_model\u001b[0m:\u001b[36mbuild\u001b[0m:\u001b[36m46\u001b[0m - \u001b[1mLSTM model built successfully.\u001b[0m\n",
            "Epoch 1/3\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m96s\u001b[0m 224ms/step - accuracy: 0.7064 - loss: 0.5377 - val_accuracy: 0.8406 - val_loss: 0.3710\n",
            "Epoch 2/3\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m133s\u001b[0m 214ms/step - accuracy: 0.8821 - loss: 0.2965 - val_accuracy: 0.8258 - val_loss: 0.4000\n",
            "Epoch 3/3\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m147s\u001b[0m 228ms/step - accuracy: 0.9153 - loss: 0.2277 - val_accuracy: 0.8387 - val_loss: 0.3909\n",
            "\u001b[32m2024-12-16 20:08:58.126\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mlstm_model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m69\u001b[0m - \u001b[1mTraining completed. Model history: {'accuracy': [0.7837200164794922, 0.8812400102615356, 0.9104400277137756], 'loss': [0.4506933093070984, 0.29767635464668274, 0.23335683345794678], 'val_accuracy': [0.8405600190162659, 0.8258000016212463, 0.8386800289154053], 'val_loss': [0.3709575831890106, 0.40004411339759827, 0.39091503620147705]}\u001b[0m\n",
            "\u001b[32m2024-12-16 20:08:58.126\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m36\u001b[0m - \u001b[1mBaseline model training complete. Saving and plotting metrics.\u001b[0m\n",
            "Plot saved to logs/Base Model_metrics.png\n",
            "Figure(1200x600)\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 43ms/step\n",
            "Base Model Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.8273    0.8560    0.8414     12500\n",
            "           1     0.8508    0.8214    0.8358     12500\n",
            "\n",
            "    accuracy                         0.8387     25000\n",
            "   macro avg     0.8391    0.8387    0.8386     25000\n",
            "weighted avg     0.8391    0.8387    0.8386     25000\n",
            "\n",
            "Base Model Confusion Matrix:\n",
            "[[10700  1800]\n",
            " [ 2233 10267]]\n",
            "\u001b[32m2024-12-16 20:09:39.908\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m45\u001b[0m - \u001b[1mPerforming membership inference attack on the baseline model.\u001b[0m\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 41ms/step\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 43ms/step\n",
            "\u001b[32m2024-12-16 20:11:01.896\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mattack_model\u001b[0m:\u001b[36mcollect_confidences\u001b[0m:\u001b[36m41\u001b[0m - \u001b[1mCollected confidences: train=25000, test=25000\u001b[0m\n",
            "\u001b[32m2024-12-16 20:11:01.896\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mattack_model\u001b[0m:\u001b[36mtrain_attack_model\u001b[0m:\u001b[36m69\u001b[0m - \u001b[1mTraining the attack model...\u001b[0m\n",
            "\u001b[32m2024-12-16 20:11:02.636\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mattack_model\u001b[0m:\u001b[36mtrain_attack_model\u001b[0m:\u001b[36m89\u001b[0m - \u001b[1mMIA Accuracy: 1.0000\u001b[0m\n",
            "\u001b[32m2024-12-16 20:11:02.636\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mattack_model\u001b[0m:\u001b[36mtrain_attack_model\u001b[0m:\u001b[36m90\u001b[0m - \u001b[1mMIA ROC-AUC: 1.0000\u001b[0m\n",
            "\u001b[32m2024-12-16 20:11:02.636\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m50\u001b[0m - \u001b[1mMIA Accuracy before privacy preservation: 1.0000\u001b[0m\n",
            "\u001b[32m2024-12-16 20:11:02.636\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m53\u001b[0m - \u001b[1mApplying regularization and early stopping techniques.\u001b[0m\n",
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n",
            "Epoch 1/10\n",
            "/usr/local/lib/python3.10/dist-packages/keras/src/optimizers/base_optimizer.py:678: UserWarning: Gradients do not exist for variables ['embeddings', 'kernel', 'recurrent_kernel', 'bias', 'kernel', 'bias'] when minimizing the loss. If using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "  warnings.warn(\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 68ms/step - accuracy: 0.5000 - loss: 1.2549 - val_accuracy: 0.5062 - val_loss: 0.6932\n",
            "Epoch 2/10\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 63ms/step - accuracy: 0.4991 - loss: 0.6932 - val_accuracy: 0.4938 - val_loss: 0.6932\n",
            "Epoch 3/10\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 64ms/step - accuracy: 0.4953 - loss: 0.6932 - val_accuracy: 0.4938 - val_loss: 0.6932\n",
            "Epoch 4/10\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 67ms/step - accuracy: 0.4955 - loss: 0.6932 - val_accuracy: 0.4938 - val_loss: 0.6933\n",
            "Epoch 5/10\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 63ms/step - accuracy: 0.4995 - loss: 0.6932 - val_accuracy: 0.4938 - val_loss: 0.6932\n",
            "Epoch 6/10\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 66ms/step - accuracy: 0.4960 - loss: 0.6932 - val_accuracy: 0.4938 - val_loss: 0.6932\n",
            "\u001b[32m2024-12-16 20:13:29.861\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m58\u001b[0m - \u001b[1mRegularized model training complete. Saving and plotting metrics.\u001b[0m\n",
            "Plot saved to logs/Regularized Model_metrics.png\n",
            "Figure(1200x600)\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 42ms/step\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "Regularized Model Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.0000    0.0000    0.0000     12500\n",
            "           1     0.5000    1.0000    0.6667     12500\n",
            "\n",
            "    accuracy                         0.5000     25000\n",
            "   macro avg     0.2500    0.5000    0.3333     25000\n",
            "weighted avg     0.2500    0.5000    0.3333     25000\n",
            "\n",
            "Regularized Model Confusion Matrix:\n",
            "[[    0 12500]\n",
            " [    0 12500]]\n",
            "\u001b[32m2024-12-16 20:14:11.300\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m69\u001b[0m - \u001b[1mPerforming membership inference attack on the regularized model.\u001b[0m\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 44ms/step\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 43ms/step\n",
            "\u001b[32m2024-12-16 20:15:26.397\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mattack_model\u001b[0m:\u001b[36mcollect_confidences\u001b[0m:\u001b[36m41\u001b[0m - \u001b[1mCollected confidences: train=25000, test=25000\u001b[0m\n",
            "\u001b[32m2024-12-16 20:15:26.398\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mattack_model\u001b[0m:\u001b[36mtrain_attack_model\u001b[0m:\u001b[36m69\u001b[0m - \u001b[1mTraining the attack model...\u001b[0m\n",
            "\u001b[32m2024-12-16 20:15:26.865\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mattack_model\u001b[0m:\u001b[36mtrain_attack_model\u001b[0m:\u001b[36m89\u001b[0m - \u001b[1mMIA Accuracy: 1.0000\u001b[0m\n",
            "\u001b[32m2024-12-16 20:15:26.865\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mattack_model\u001b[0m:\u001b[36mtrain_attack_model\u001b[0m:\u001b[36m90\u001b[0m - \u001b[1mMIA ROC-AUC: 1.0000\u001b[0m\n",
            "\u001b[32m2024-12-16 20:15:26.865\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m77\u001b[0m - \u001b[1mMIA Accuracy after applying regularization: 1.0000\u001b[0m\n",
            "\u001b[32m2024-12-16 20:15:26.866\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m80\u001b[0m - \u001b[1mComparing MIA accuracy results and visualizing.\u001b[0m\n",
            "MIA comparison plot saved to logs/mia_comparison.png\n",
            "Figure(800x600)\n",
            "\u001b[32m2024-12-16 20:15:26.981\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m91\u001b[0m - \u001b[1mResults comparison saved to logs.\u001b[0m\n",
            "\u001b[32m2024-12-16 20:15:26.981\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m107\u001b[0m - \u001b[1mMain process complete.\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "%cd /content/AIX/NLP-task-MIA/src\n",
        "!python main.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BL-55HmKLJ1a"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "authorship_tag": "ABX9TyMXZ38z/Dr7mnzgBqjkVsV/",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}